{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Qt1fGUB0Vz.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>j4Rhioq7R3.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rD0hgFHJUZ.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aY5z1EJsJ6.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>qZ3IoxD2TE.jpeg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                id\n",
       "0  Qt1fGUB0Vz.jpeg\n",
       "1  j4Rhioq7R3.jpeg\n",
       "2  rD0hgFHJUZ.jpeg\n",
       "3  aY5z1EJsJ6.jpeg\n",
       "4  qZ3IoxD2TE.jpeg"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Load data from CSV files\n",
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "sample_df = pd.read_csv('sample_submission.csv')\n",
    "\n",
    "test_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training images: 724\n",
      "Number of training labels: 724\n",
      "Number of test images: 365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 810ms/step - accuracy: 0.9290 - loss: 0.8188\n",
      "Epoch 2/15\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 819ms/step - accuracy: 0.9164 - loss: 0.2871\n",
      "Epoch 3/15\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 812ms/step - accuracy: 0.9355 - loss: 0.2128\n",
      "Epoch 4/15\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 822ms/step - accuracy: 0.9369 - loss: 0.1545\n",
      "Epoch 5/15\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 825ms/step - accuracy: 0.9838 - loss: 0.0742\n",
      "Epoch 6/15\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 805ms/step - accuracy: 0.9938 - loss: 0.0246\n",
      "Epoch 7/15\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 816ms/step - accuracy: 0.9974 - loss: 0.0171\n",
      "Epoch 8/15\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 806ms/step - accuracy: 0.9918 - loss: 0.0347\n",
      "Epoch 9/15\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 820ms/step - accuracy: 1.0000 - loss: 0.0071\n",
      "Epoch 10/15\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 831ms/step - accuracy: 1.0000 - loss: 0.0023\n",
      "Epoch 11/15\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 819ms/step - accuracy: 1.0000 - loss: 0.0010\n",
      "Epoch 12/15\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 847ms/step - accuracy: 1.0000 - loss: 4.2137e-04\n",
      "Epoch 13/15\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 839ms/step - accuracy: 1.0000 - loss: 4.0028e-04\n",
      "Epoch 14/15\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 829ms/step - accuracy: 1.0000 - loss: 2.8891e-04\n",
      "Epoch 15/15\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 848ms/step - accuracy: 1.0000 - loss: 3.0787e-04\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 199ms/step\n",
      "Model training and prediction complete. Predictions saved to 'sample_submission.csv'.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define preprocessing function\n",
    "def preprocess_image(image):\n",
    "    target_size = (224, 224)\n",
    "    if image is None:\n",
    "        print(f\"Error: Unable to load image\")\n",
    "        return None\n",
    "    image = cv2.resize(image, target_size)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = image.astype('float32') / 255.0\n",
    "    return image\n",
    "\n",
    "# Initialize lists to store images and labels\n",
    "train_images = []\n",
    "train_labels = []\n",
    "test_images = []\n",
    "\n",
    "# Load and preprocess images from the folder\n",
    "folder_path = 'images'\n",
    "image_extensions = (\".jpg\", \".jpeg\", \".png\", \".webp\")\n",
    "\n",
    "# Set of train and test image IDs\n",
    "train_ids = set(train_df['id'])\n",
    "test_ids = set(test_df['id'])\n",
    "\n",
    "# Process all images in the folder\n",
    "all_image_files = [f for f in os.listdir(folder_path) if f.lower().endswith(image_extensions)]\n",
    "valid_test_ids = []\n",
    "\n",
    "for filename in all_image_files:\n",
    "    image_path = os.path.join(folder_path, filename)\n",
    "    image = cv2.imread(image_path)\n",
    "    preprocessed_image = preprocess_image(image)\n",
    "    \n",
    "    if preprocessed_image is not None:\n",
    "        if filename in train_ids:\n",
    "            train_images.append(preprocessed_image)\n",
    "            train_labels.append(train_df[train_df['id'] == filename]['target'].values[0])\n",
    "        elif filename in test_ids:\n",
    "            test_images.append(preprocessed_image)\n",
    "            valid_test_ids.append(filename)\n",
    "\n",
    "# Convert lists of images and labels to NumPy arrays\n",
    "train_images = np.array(train_images)\n",
    "train_labels = np.array(train_labels)\n",
    "test_images = np.array(test_images)\n",
    "\n",
    "# Verify that we have the correct number of images\n",
    "print(f\"Number of training images: {len(train_images)}\")\n",
    "print(f\"Number of training labels: {len(train_labels)}\")\n",
    "print(f\"Number of test images: {len(test_images)}\")\n",
    "\n",
    "# Define model architecture\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_images, train_labels, epochs=15, batch_size=32)\n",
    "\n",
    "# Ensure there are test images to predict\n",
    "if len(test_images) > 0:\n",
    "    # Predict labels for test images\n",
    "    test_predictions = model.predict(test_images).flatten()\n",
    "\n",
    "    # Convert predictions to binary (0 or 1)\n",
    "    test_predictions = (test_predictions > 0.5).astype(int)\n",
    "\n",
    "    # Filter the test_df to only include valid images\n",
    "    filtered_test_df = test_df[test_df['id'].isin(valid_test_ids)].copy()\n",
    "    filtered_test_df['target'] = test_predictions\n",
    "\n",
    "    # Save predictions to a CSV file\n",
    "    filtered_test_df[['id', 'target']].to_csv('sample_submission.csv', index=False)\n",
    "\n",
    "    print(\"Model training and prediction complete. Predictions saved to 'sample_submission.csv'.\")\n",
    "else:\n",
    "    print(\"No test images found. Prediction step skipped.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
